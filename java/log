19/11/05 23:19:50 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL
19/11/05 23:19:50 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType
19/11/05 23:19:50 INFO pig.Main: Loaded log4j properties from file: /etc/pig/conf/log4j.properties
37   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r: unknown) compiled Jul 01 2019, 22:56:40
19/11/05 23:19:50 INFO pig.Main: Apache Pig version 0.17.0 (r: unknown) compiled Jul 01 2019, 22:56:40
38   [main] INFO  org.apache.pig.Main  - Logging error messages to: /mnt/var/log/pig/pig_1572995990636.log
19/11/05 23:19:50 INFO pig.Main: Logging error messages to: /mnt/var/log/pig/pig_1572995990636.log
19/11/05 23:19:50 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
281  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /home/hadoop/.pigbootup not found
19/11/05 23:19:50 INFO util.Utils: Default bootup file /home/hadoop/.pigbootup not found
19/11/05 23:19:50 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
385  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: file:///
19/11/05 23:19:50 INFO executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
529  [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-test.pig-3d8a3227-0c76-49e1-a9c9-7e14cfd1166f
19/11/05 23:19:51 INFO pig.PigServer: Pig Script ID for the session: PIG-test.pig-3d8a3227-0c76-49e1-a9c9-7e14cfd1166f
529  [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
19/11/05 23:19:51 WARN pig.PigServer: ATS is disabled since yarn.timeline-service.enabled set to false
1217 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: UNKNOWN
19/11/05 23:19:51 INFO pigstats.ScriptState: Pig features used in the script: UNKNOWN
1308 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
19/11/05 23:19:51 INFO optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
1327 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for records: $1
19/11/05 23:19:51 INFO rules.ColumnPruneVisitor: Columns pruned for records: $1
1407 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
19/11/05 23:19:52 INFO util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
1452 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
19/11/05 23:19:52 INFO mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
1469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 1
19/11/05 23:19:52 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
1469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 1
19/11/05 23:19:52 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
19/11/05 23:19:52 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/11/05 23:19:52 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
1518 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/11/05 23:19:52 INFO mapreduce.MRScriptState: Pig script settings are added to the job
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
1522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/11/05 23:19:52 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
1533 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/11/05 23:19:52 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/11/05 23:19:52 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/11/05 23:19:52 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1572995992140-0
19/11/05 23:19:52 INFO data.SchemaTupleFrontend: Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1572995992140-0
1574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
19/11/05 23:19:52 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/11/05 23:19:52 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
1637 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/11/05 23:19:52 INFO builtin.PigStorage: Using PigTextInputFormat
19/11/05 23:19:52 INFO input.FileInputFormat: Total input files to process : 1
1640 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/11/05 23:19:52 INFO util.MapRedUtil: Total input paths to process : 1
1651 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/11/05 23:19:52 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/11/05 23:19:52 INFO mapreduce.JobSubmitter: number of splits:1
19/11/05 23:19:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local433318118_0001
19/11/05 23:19:52 WARN conf.Configuration: file:/tmp/hadoop-hadoop/mapred/staging/hadoop433318118/.staging/job_local433318118_0001/job.xml:an attempt to override final parameter: yarn.nodemanager.local-dirs;  Ignoring.
19/11/05 23:19:52 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/11/05 23:19:52 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/11/05 23:19:52 INFO Configuration.deprecation: mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
19/11/05 23:19:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/05 23:19:52 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/05 23:19:52 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED
19/11/05 23:19:52 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
19/11/05 23:19:52 INFO mapred.LocalJobRunner: Waiting for map tasks
19/11/05 23:19:52 INFO mapred.LocalJobRunner: Starting task: attempt_local433318118_0001_m_000000_0
19/11/05 23:19:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/05 23:19:52 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/05 23:19:52 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED
19/11/05 23:19:52 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/11/05 23:19:52 INFO mapred.MapTask: Processing split: Number of splits :1
Total Length = 49
Input split[0]:
   Length = 49
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------

2036 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/11/05 23:19:52 INFO builtin.PigStorage: Using PigTextInputFormat
2039 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader  - Current split being processed file:/home/hadoop/temp.txt:0+49
19/11/05 23:19:52 INFO mapReduceLayer.PigRecordReader: Current split being processed file:/home/hadoop/temp.txt:0+49
19/11/05 23:19:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/05 23:19:52 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/05 23:19:52 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED
19/11/05 23:19:52 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
19/11/05 23:19:52 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev dd4c76892e34528885afc09320477261050f9ab5]
2059 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
19/11/05 23:19:52 INFO util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2060 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
19/11/05 23:19:52 INFO data.SchemaTupleBackend: Key [pig.schematuple] was not set... will not generate code.
19/11/05 23:19:52 INFO mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: records[1,10],records[-1,-1],hbase_result[6,15] C:  R: 
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local433318118_0001
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: Processing aliases hbase_result,records
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: records[1,10],records[-1,-1],hbase_result[6,15] C:  R: 
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: 0% complete
19/11/05 23:19:52 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_local433318118_0001]
19/11/05 23:19:52 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:52 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:52 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:52 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
19/11/05 23:19:53 DEBUG impl.DfsClientConf: dfs.client.read.shortcircuit = false
19/11/05 23:19:53 DEBUG impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
19/11/05 23:19:53 DEBUG impl.DfsClientConf: dfs.domain.socket.path = 
19/11/05 23:19:53 DEBUG hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
19/11/05 23:19:53 DEBUG retry.RetryUtils: multipleLinearRandomRetry = null
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1362d276
19/11/05 23:19:53 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@135c89c9
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG unix.DomainSocketWatcher: org.apache.hadoop.net.unix.DomainSocketWatcher$2@3d016488: starting with interruptCheckPeriodMs = 60000
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
19/11/05 23:19:53 DEBUG sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
19/11/05 23:19:53 DEBUG logging.InternalLoggerFactory: Using SLF4J as the default logging framework
19/11/05 23:19:53 DEBUG util.ResourceLeakDetector: -Dio.netty.leakDetectionLevel: simple
19/11/05 23:19:53 DEBUG internal.PlatformDependent0: java.nio.Buffer.address: available
19/11/05 23:19:53 DEBUG internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
19/11/05 23:19:53 DEBUG internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
19/11/05 23:19:53 DEBUG internal.PlatformDependent0: java.nio.Bits.unaligned: true
19/11/05 23:19:53 DEBUG internal.PlatformDependent: UID: 498
19/11/05 23:19:53 DEBUG internal.PlatformDependent: Java version: 8
19/11/05 23:19:53 DEBUG internal.PlatformDependent: -Dio.netty.noUnsafe: false
19/11/05 23:19:53 DEBUG internal.PlatformDependent: sun.misc.Unsafe: available
19/11/05 23:19:53 DEBUG internal.PlatformDependent: -Dio.netty.noJavassist: false
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG internal.PlatformDependent: Javassist: available
19/11/05 23:19:53 DEBUG internal.PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
19/11/05 23:19:53 DEBUG internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
19/11/05 23:19:53 DEBUG internal.PlatformDependent: -Dio.netty.noPreferDirect: false
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.hbase.ipc.BlockingRpcConnection.setupIOstreams(BlockingRpcConnection.java:452)
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 578
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 122
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 122
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 122
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 124
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 124
19/11/05 23:19:53 DEBUG security.SaslInputStream: Actual length is 122
19/11/05 23:19:53 INFO mapred.LocalJobRunner: 
19/11/05 23:19:53 INFO mapred.Task: Task:attempt_local433318118_0001_m_000000_0 is done. And is in the process of committing
19/11/05 23:19:53 INFO mapred.LocalJobRunner: 
19/11/05 23:19:53 INFO mapred.Task: Task attempt_local433318118_0001_m_000000_0 is allowed to commit now
19/11/05 23:19:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local433318118_0001_m_000000_0' to file:/tmp/temp-55608675/tmp395672203/_temporary/0/task_local433318118_0001_m_000000
19/11/05 23:19:53 INFO mapred.LocalJobRunner: map
19/11/05 23:19:53 INFO mapred.Task: Task 'attempt_local433318118_0001_m_000000_0' done.
19/11/05 23:19:53 INFO mapred.Task: Final Counters for attempt_local433318118_0001_m_000000_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=456
		FILE: Number of bytes written=421462
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=0
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Input split bytes=353
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=460324864
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
19/11/05 23:19:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local433318118_0001_m_000000_0
19/11/05 23:19:53 INFO mapred.LocalJobRunner: map task executor complete.
19/11/05 23:19:53 DEBUG output.FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/tmp/temp-55608675/tmp395672203/_temporary/0/task_local433318118_0001_m_000000; isDirectory=true; modification_time=1572995992000; access_time=1572995992641; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/tmp/temp-55608675/tmp395672203
19/11/05 23:19:53 DEBUG output.FileOutputCommitter: Merging data from DeprecatedRawLocalFileStatus{path=file:/tmp/temp-55608675/tmp395672203/_temporary/0/task_local433318118_0001_m_000000/part-m-00000; isDirectory=false; length=136; replication=1; blocksize=33554432; modification_time=1572995993000; access_time=1572995992641; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/tmp/temp-55608675/tmp395672203/part-m-00000
19/11/05 23:19:53 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339)
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskReports(Job.java:536)
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskReports(Job.java:536)
19/11/05 23:19:54 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/11/05 23:19:54 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:809)
19/11/05 23:19:54 INFO mapReduceLayer.MapReduceLauncher: 100% complete
19/11/05 23:19:54 INFO mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.5-amzn-4	0.17.0	hadoop	2019-11-05 23:19:52	2019-11-05 23:19:54	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local433318118_0001	1	0	n/a	n/a	n/a	n/a	0	0	0	0	hbase_result,records	MAP_ONLY	file:/tmp/temp-55608675/tmp395672203,

Input(s):
Successfully read 6 records from: "/home/hadoop/temp.txt"

Output(s):
Successfully stored 6 records in: "file:/tmp/temp-55608675/tmp395672203"

Counters:
Total records written : 6
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local433318118_0001


19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskReports(Job.java:536)
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskReports(Job.java:536)
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19/11/05 23:19:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/11/05 23:19:54 DEBUG mapreduce.Cluster: Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19/11/05 23:19:54 DEBUG security.UserGroupInformation: PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:809)
19/11/05 23:19:54 INFO mapReduceLayer.MapReduceLauncher: Success!
19/11/05 23:19:54 WARN data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
19/11/05 23:19:54 DEBUG input.FileInputFormat: Time taken to get FileStatuses: 9
19/11/05 23:19:54 INFO input.FileInputFormat: Total input files to process : 1
19/11/05 23:19:54 INFO util.MapRedUtil: Total input paths to process : 1
19/11/05 23:19:54 DEBUG input.FileInputFormat: Total # of splits generated by getSplits: 1, TimeTaken: 9
(1990,90finish)
(1990,90finish)
(1991,91finish)
(1992,92progress)
(1992,92progress)
(1990,90finish)
19/11/05 23:19:54 INFO pig.Main: Pig script completed in 3 seconds and 977 milliseconds (3977 ms)
19/11/05 23:19:54 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@135c89c9
19/11/05 23:19:54 DEBUG ipc.Client: removing client from cache: org.apache.hadoop.ipc.Client@135c89c9
19/11/05 23:19:54 DEBUG ipc.Client: stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@135c89c9
19/11/05 23:19:54 DEBUG ipc.Client: Stopping client
19/11/05 23:19:54 DEBUG util.ShutdownHookManager: ShutdownHookManger complete shutdown.
